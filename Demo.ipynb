{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SKD7jSvIn1T9"
   },
   "source": [
    "# Importing Modules\n",
    "\n",
    "The necessary modules are : os, opencv, numpy, tqdm, matplotlib, keras and sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nNtz_YYVnzcZ",
    "outputId": "21000b0d-93c5-4dcf-96f3-4bedc5d90a3c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, BatchNormalization, Activation, add\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.advanced_activations import ELU, LeakyReLU\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras import backend as K \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fb1Dw_RroBkh"
   },
   "source": [
    "# Downloading Data\n",
    "\n",
    "Here, we download the image data and the corresponding ground truth segmentation masks.\n",
    "\n",
    "In the paper we had not tested on the ISIC-17 Dataset, which will be used here for the demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u5MQHA30oWEl"
   },
   "source": [
    "## Downloading the Images\n",
    "\n",
    "Please note that the links may be different when you are running this notebook. Please update the link accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py): started\n",
      "  Building wheel for wget (setup.py): finished with status 'done'\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9680 sha256=8f0e415b5a510fcc8d48b52dbf96ad65a2ee64dde228d99f9e862cd445b41139\n",
      "  Stored in directory: c:\\users\\computer\\appdata\\local\\pip\\cache\\wheels\\e1\\e8\\db\\ebe4dcd7d7d11208c1e4e4ef246cea4fcc8d463c93405a6555\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "# !pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "XrMkfbme0nG_",
    "outputId": "d3a31f2d-5e1d-4fc4-8796-79a135c287a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved under ISIC_2017_images.zip\n"
     ]
    }
   ],
   "source": [
    "# !python -m wget -o \"ISIC_2017_images.zip\" https://isic-challenge-data.s3.amazonaws.com/2017/ISIC-2017_Training_Data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UCQn7FSHoiTk"
   },
   "source": [
    "## Downloading the Ground Truth Segmentation\n",
    "\n",
    "Please note that the links may be different when you are running this notebook. Please update the link accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "enE3vtZr1G5X",
    "outputId": "93e2377b-3359-410a-d9b0-d3356d1d422c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved under ISIC_2017_masks.zip\n"
     ]
    }
   ],
   "source": [
    "# !python -m wget -o \"ISIC_2017_masks.zip\" https://isic-challenge-data.s3.amazonaws.com/2017/ISIC-2017_Training_Part1_GroundTruth.zip\n",
    "\n",
    "# ! wget \"https://challenge.kitware.com/api/v1/item/584997d0cad3a51cc66c8e00/download\" -O ISIC_2017_masks.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2YFLs2aFoxgN"
   },
   "source": [
    "## Extracting the Zip Files\n",
    "\n",
    "Next the downloaded zip files are unzipped and the data is extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile('ISIC_2017_images.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('ISIC_2017_images')\n",
    "# with zipfile.ZipFile('ISIC_2017_masks.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('ISIC_2017_masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pCy-G3jH2E9D"
   },
   "outputs": [],
   "source": [
    "# !python -m unzip ISIC_2017_images.zip -d ISIC_2017_images\n",
    "# !python -m unzip ISIC_2017_masks.zip -d ISIC_2017_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xLkeS7Lxo_Po"
   },
   "source": [
    "# Constructing Training and Test Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gHo6ymwFpJzY"
   },
   "source": [
    "## Loading the Images\n",
    "\n",
    "We first load all the images and the corresponding segmentation masks. \n",
    "\n",
    "They are stored in two lists X, Y and respectively\n",
    "\n",
    "Moreover, the images are resized to 256x192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "YbeQ1aytHTm3",
    "outputId": "d43c1e52-d889-4a4f-96aa-5ef4d20b649f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4001\n",
      "2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4001/4001 [03:41<00:00, 18.10it/s]\n"
     ]
    }
   ],
   "source": [
    "img_files = next(os.walk('ISIC_2017_images/ISIC-2017_Training_Data'))[2]\n",
    "msk_files = next(os.walk('ISIC_2017_masks/ISIC-2017_Training_Part1_GroundTruth'))[2]\n",
    "\n",
    "img_files.sort()\n",
    "msk_files.sort()\n",
    "\n",
    "print(len(img_files))\n",
    "print(len(msk_files))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for img_fl in tqdm(img_files):    \n",
    "    if(img_fl.split('.')[-1]=='jpg'):\n",
    "        \n",
    "        img = cv2.imread('ISIC_2017_images/ISIC-2017_Training_Data/{}'.format(img_fl), cv2.IMREAD_COLOR)\n",
    "        resized_img = cv2.resize(img,(256, 192), interpolation = cv2.INTER_CUBIC)\n",
    "        \n",
    "        X.append(resized_img)\n",
    "        \n",
    "        msk = cv2.imread('ISIC_2017_masks/ISIC-2017_Training_Part1_GroundTruth/{}'.format(img_fl.split('.')[0]+'_segmentation.png'), cv2.IMREAD_GRAYSCALE)\n",
    "        resized_msk = cv2.resize(msk,(256, 192), interpolation = cv2.INTER_CUBIC)\n",
    "        \n",
    "        Y.append(resized_msk)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jYgEz9HQpgsR"
   },
   "source": [
    "## Train-Test Split\n",
    "\n",
    "The X, Y lists are converted to numpy arrays for convenience. \n",
    "Furthermore, the images are divided by 255 to bring down the pixel values to [0...1] range. On the other hand the segmentations masks are converted to binary (0 or 1) values.\n",
    "\n",
    "Using Sklearn *train_test_split* we split the data randomly into 80% training and 20% testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "CxFIZv3715Dt",
    "outputId": "5a93db60-ed50-4122-8aa0-b26e42a601ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2000\n",
      "(1600, 192, 256, 3)\n",
      "(1600, 192, 256, 1)\n",
      "(400, 192, 256, 3)\n",
      "(400, 192, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "print(len(X))\n",
    "print(len(Y))\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=3)\n",
    "\n",
    "Y_train = Y_train.reshape((Y_train.shape[0],Y_train.shape[1],Y_train.shape[2],1))\n",
    "Y_test = Y_test.reshape((Y_test.shape[0],Y_test.shape[1],Y_test.shape[2],1))\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "Y_train = Y_train / 255\n",
    "Y_test = Y_test / 255\n",
    "\n",
    "Y_train = np.round(Y_train,0)\t\n",
    "Y_test = np.round(Y_test,0)\t\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C-Ajp2QVrMti"
   },
   "source": [
    "# MultiResUNet Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "21cbmiojrYrU"
   },
   "source": [
    "## Model Definition\n",
    "\n",
    "The MultiResUNet model as described in the [paper](https://arxiv.org/abs/1902.04049) can be found  [here](https://github.com/nibtehaz/MultiResUNet/blob/master/MultiResUNet.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2nX7I1Wf_zEy"
   },
   "outputs": [],
   "source": [
    "def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), activation='relu', name=None):\n",
    "    '''\n",
    "    2D Convolutional layers\n",
    "    \n",
    "    Arguments:\n",
    "        x {keras layer} -- input layer \n",
    "        filters {int} -- number of filters\n",
    "        num_row {int} -- number of rows in filters\n",
    "        num_col {int} -- number of columns in filters\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        padding {str} -- mode of padding (default: {'same'})\n",
    "        strides {tuple} -- stride of convolution operation (default: {(1, 1)})\n",
    "        activation {str} -- activation function (default: {'relu'})\n",
    "        name {str} -- name of the layer (default: {None})\n",
    "    \n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False)(x)\n",
    "    x = BatchNormalization(axis=3, scale=False)(x)\n",
    "\n",
    "    if(activation == None):\n",
    "        return x\n",
    "\n",
    "    x = Activation(activation, name=name)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def trans_conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(2, 2), name=None):\n",
    "    '''\n",
    "    2D Transposed Convolutional layers\n",
    "    \n",
    "    Arguments:\n",
    "        x {keras layer} -- input layer \n",
    "        filters {int} -- number of filters\n",
    "        num_row {int} -- number of rows in filters\n",
    "        num_col {int} -- number of columns in filters\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        padding {str} -- mode of padding (default: {'same'})\n",
    "        strides {tuple} -- stride of convolution operation (default: {(2, 2)})\n",
    "        name {str} -- name of the layer (default: {None})\n",
    "    \n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    x = Conv2DTranspose(filters, (num_row, num_col), strides=strides, padding=padding)(x)\n",
    "    x = BatchNormalization(axis=3, scale=False)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def MultiResBlock(U, inp, alpha = 1.67):\n",
    "    '''\n",
    "    MultiRes Block\n",
    "    \n",
    "    Arguments:\n",
    "        U {int} -- Number of filters in a corrsponding UNet stage\n",
    "        inp {keras layer} -- input layer \n",
    "    \n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    W = alpha * U\n",
    "\n",
    "    shortcut = inp\n",
    "\n",
    "    shortcut = conv2d_bn(shortcut, int(W*0.167) + int(W*0.333) +\n",
    "                         int(W*0.5), 1, 1, activation=None, padding='same')\n",
    "\n",
    "    conv3x3 = conv2d_bn(inp, int(W*0.167), 3, 3,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    conv5x5 = conv2d_bn(conv3x3, int(W*0.333), 3, 3,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    conv7x7 = conv2d_bn(conv5x5, int(W*0.5), 3, 3,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    out = concatenate([conv3x3, conv5x5, conv7x7], axis=3)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    out = add([shortcut, out])\n",
    "    out = Activation('relu')(out)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def ResPath(filters, length, inp):\n",
    "    '''\n",
    "    ResPath\n",
    "    \n",
    "    Arguments:\n",
    "        filters {int} -- [description]\n",
    "        length {int} -- length of ResPath\n",
    "        inp {keras layer} -- input layer \n",
    "    \n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "\n",
    "    shortcut = inp\n",
    "    shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
    "                         activation=None, padding='same')\n",
    "\n",
    "    out = conv2d_bn(inp, filters, 3, 3, activation='relu', padding='same')\n",
    "\n",
    "    out = add([shortcut, out])\n",
    "    out = Activation('relu')(out)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    for i in range(length-1):\n",
    "\n",
    "        shortcut = out\n",
    "        shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
    "                             activation=None, padding='same')\n",
    "\n",
    "        out = conv2d_bn(out, filters, 3, 3, activation='relu', padding='same')\n",
    "\n",
    "        out = add([shortcut, out])\n",
    "        out = Activation('relu')(out)\n",
    "        out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def MultiResUnet(height, width, n_channels):\n",
    "    '''\n",
    "    MultiResUNet\n",
    "    \n",
    "    Arguments:\n",
    "        height {int} -- height of image \n",
    "        width {int} -- width of image \n",
    "        n_channels {int} -- number of channels in image\n",
    "    \n",
    "    Returns:\n",
    "        [keras model] -- MultiResUNet model\n",
    "    '''\n",
    "\n",
    "\n",
    "    inputs = Input((height, width, n_channels))\n",
    "\n",
    "    mresblock1 = MultiResBlock(32, inputs)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(mresblock1)\n",
    "    mresblock1 = ResPath(32, 4, mresblock1)\n",
    "\n",
    "    mresblock2 = MultiResBlock(32*2, pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(mresblock2)\n",
    "    mresblock2 = ResPath(32*2, 3, mresblock2)\n",
    "\n",
    "    mresblock3 = MultiResBlock(32*4, pool2)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(mresblock3)\n",
    "    mresblock3 = ResPath(32*4, 2, mresblock3)\n",
    "\n",
    "    mresblock4 = MultiResBlock(32*8, pool3)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(mresblock4)\n",
    "    mresblock4 = ResPath(32*8, 1, mresblock4)\n",
    "\n",
    "    mresblock5 = MultiResBlock(32*16, pool4)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(\n",
    "        32*8, (2, 2), strides=(2, 2), padding='same')(mresblock5), mresblock4], axis=3)\n",
    "    mresblock6 = MultiResBlock(32*8, up6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(\n",
    "        32*4, (2, 2), strides=(2, 2), padding='same')(mresblock6), mresblock3], axis=3)\n",
    "    mresblock7 = MultiResBlock(32*4, up7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(\n",
    "        32*2, (2, 2), strides=(2, 2), padding='same')(mresblock7), mresblock2], axis=3)\n",
    "    mresblock8 = MultiResBlock(32*2, up8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(\n",
    "        2, 2), padding='same')(mresblock8), mresblock1], axis=3)\n",
    "    mresblock9 = MultiResBlock(32, up9)\n",
    "\n",
    "    conv10 = conv2d_bn(mresblock9, 1, 1, 1, activation='sigmoid')\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2frZlpmFsv1f"
   },
   "source": [
    "## Auxiliary Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "degBGBWYsyNG"
   },
   "source": [
    "### Custom Metrics\n",
    "\n",
    "Since Keras does not have build-in support for computing Dice Coefficient or Jaccard Index (at the time of writing), the following functions are declared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xq8qfLqDA6q2"
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 0.0\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def jacard(y_true, y_pred):\n",
    "\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum ( y_true_f * y_pred_f)\n",
    "    union = K.sum ( y_true_f + y_pred_f - y_true_f * y_pred_f)\n",
    "\n",
    "    return intersection/union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VtvyeBXy8Mk3"
   },
   "source": [
    "### Saving Model \n",
    "\n",
    "Function to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GCfX9MUYALar"
   },
   "outputs": [],
   "source": [
    "def saveModel(model):\n",
    "\n",
    "    model_json = model.to_json()\n",
    "\n",
    "    try:\n",
    "        os.makedirs('models')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    fp = open('models/modelP.json','w')\n",
    "    fp.write(model_json)\n",
    "    model.save_weights('models/modelW.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AH3znjx-8vDq"
   },
   "source": [
    "### Evaluate the Model\n",
    "\n",
    "We evaluate the model on test data (X_test, Y_test). \n",
    "\n",
    "We compute the values of Jaccard Index and Dice Coeficient, and save the predicted segmentation of first 10 images. The best model is also saved\n",
    "\n",
    "(This could have been done using keras call-backs as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tkit_YYvBQ7V"
   },
   "outputs": [],
   "source": [
    "def evaluateModel(model, X_test, Y_test, batchSize):\n",
    "    \n",
    "    try:\n",
    "        os.makedirs('results')\n",
    "    except:\n",
    "        pass \n",
    "    \n",
    "\n",
    "    yp = model.predict(x=X_test, batch_size=batchSize, verbose=1)\n",
    "\n",
    "    yp = np.round(yp,0)\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.imshow(X_test[i])\n",
    "        plt.title('Input')\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.imshow(Y_test[i].reshape(Y_test[i].shape[0],Y_test[i].shape[1]))\n",
    "        plt.title('Ground Truth')\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.imshow(yp[i].reshape(yp[i].shape[0],yp[i].shape[1]))\n",
    "        plt.title('Prediction')\n",
    "\n",
    "        intersection = yp[i].ravel() * Y_test[i].ravel()\n",
    "        union = yp[i].ravel() + Y_test[i].ravel() - intersection\n",
    "\n",
    "        jacard = (np.sum(intersection)/np.sum(union))  \n",
    "        plt.suptitle('Jacard Index'+ str(np.sum(intersection)) +'/'+ str(np.sum(union)) +'='+str(jacard))\n",
    "\n",
    "        plt.savefig('results/'+str(i)+'.png',format='png')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    jacard = 0\n",
    "    dice = 0\n",
    "    \n",
    "    \n",
    "    for i in range(len(Y_test)):\n",
    "        yp_2 = yp[i].ravel()\n",
    "        y2 = Y_test[i].ravel()\n",
    "        \n",
    "        intersection = yp_2 * y2\n",
    "        union = yp_2 + y2 - intersection\n",
    "\n",
    "        jacard += (np.sum(intersection)/np.sum(union))  \n",
    "\n",
    "        dice += (2. * np.sum(intersection) ) / (np.sum(yp_2) + np.sum(y2))\n",
    "\n",
    "    \n",
    "    jacard /= len(Y_test)\n",
    "    dice /= len(Y_test)\n",
    "    \n",
    "\n",
    "\n",
    "    print('Jacard Index : '+str(jacard))\n",
    "    print('Dice Coefficient : '+str(dice))\n",
    "    \n",
    "\n",
    "    fp = open('models/log.txt','a')\n",
    "    fp.write(str(jacard)+'\\n')\n",
    "    fp.close()\n",
    "\n",
    "    fp = open('models/best.txt','r')\n",
    "    best = fp.read()\n",
    "    fp.close()\n",
    "\n",
    "    if(jacard>float(best)):\n",
    "        print('***********************************************')\n",
    "        print('Jacard Index improved from '+str(best)+' to '+str(jacard))\n",
    "        print('***********************************************')\n",
    "        fp = open('models/best.txt','w')\n",
    "        fp.write(str(jacard))\n",
    "        fp.close()\n",
    "\n",
    "        saveModel(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "80IwnKtM9NHY"
   },
   "source": [
    "### Training the Model\n",
    "\n",
    "The model is trained and evaluated after each epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wlOOh0-nA05L"
   },
   "outputs": [],
   "source": [
    "def trainStep(model, X_train, Y_train, X_test, Y_test, epochs, batchSize):\n",
    "\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch : {}'.format(epoch+1))\n",
    "        model.fit(x=X_train, y=Y_train, batch_size=batchSize, epochs=1, verbose=1)     \n",
    "\n",
    "        evaluateModel(model,X_test, Y_test,batchSize)\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4wJ5V9AJ9Ygu"
   },
   "source": [
    "## Define Model, Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1105
    },
    "colab_type": "code",
    "id": "GJqeuZPhDZSK",
    "outputId": "b1344374-f69e-4805-a22d-b8152f07b754"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MultiResUnet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21140\\3140655213.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultiResUnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m192\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_channels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdice_coef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjacard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_accuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msaveModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MultiResUnet' is not defined"
     ]
    }
   ],
   "source": [
    "model = MultiResUnet(height=192, width=256, n_channels=3)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef, jacard, categorical_accuracy])\n",
    "\n",
    "saveModel(model)\n",
    "\n",
    "fp = open('models/log.txt','w')\n",
    "fp.close()\n",
    "fp = open('models/best.txt','w')\n",
    "fp.write('-1.0')\n",
    "fp.close()\n",
    "    \n",
    "trainStep(model, X_train, Y_train, X_test, Y_test, epochs=10, batchSize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ISIC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:multiresunet]",
   "language": "python",
   "name": "conda-env-multiresunet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
